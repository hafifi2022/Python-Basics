{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain our data from a variety of sources such as databases, web API’s but a common way  to obtain data is through \n",
    "# a good old fashioned file. \n",
    "# So in this section, we will use a lot of what we have learnt so far to deal with reading data from and writing to files.\n",
    "\n",
    "# Python can read files pretty easily from the standard library. Its just a case of specifying where the file is and then \n",
    "# creating a stream to that location. \n",
    "# Let’s demonstrate by having a file located in /Path/to/file/test.csv. \n",
    "# This is the full path to the comma separated file test.csv.\n",
    "\n",
    "import os\n",
    "\n",
    "x = os.getcwd()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAFIFI\\Documents\\Python Jupyter Notebook\\The Python Book\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\test.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"\\\\Files\\\\test.csv\"\n",
    "file_path = x + file_name\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\test.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(file_path,\"r\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hp,dell,ibm,asus,lenovo,fujitsu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we have done here is define a string file_name containing the name of the file and then used the \n",
    "# open command with the arguments of file_name and ‘r’ which is the mode to read the file in and in this \n",
    "# case it refers to read. We have assigned the return of this to the variable f which is a stream to the \n",
    "# file. Now to read in the data from the file we simply run:\n",
    "\n",
    "data = f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'steve\\ntony\\nbruce\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we get back is the data in a single index list, which isn’t that useful. In text files\n",
    "# what you find is that lines are separated by a line return which means that we could apply\n",
    "# the split method which will split what it reads into new elements of the list every time it\n",
    "# sees a line return. Its easier to demonstrate this by an example on a string:\n",
    "\n",
    "names = \"steve\\ntony\\nbruce\\n\"\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve\n",
      "tony\n",
      "bruce\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['steve', 'tony', 'bruce', '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hp', 'dell', 'ibm', 'asus', 'lenovo', 'fujitsu']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case:\n",
    "\n",
    "f = open(file_path,\"r\")\n",
    "data = f.read().split(\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve,rodgers\n",
      "tony,stark\n",
      "bruce,banner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With a comma separated file we have each item on a given line separated by a comma.\n",
    "# So to get each item we need to split again based on a comma. \n",
    "# For the following:\n",
    "\n",
    "names = \"steve,rodgers\\ntony,stark\\nbruce,banner\\n\"\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['steve,rodgers', 'tony,stark', 'bruce,banner', '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = names.split(\"\\n\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve,rodgers\n",
      "tony,stark\n",
      "bruce,banner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in names:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'steve,rodgers'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['steve', 'rodgers']\n",
      "['tony', 'stark']\n",
      "['bruce', 'banner']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "for n in names:\n",
    "    row = n.split(\",\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['steve', 'rodgers']\n",
      "['tony', 'stark']\n",
      "['bruce', 'banner']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "names_row = []\n",
    "\n",
    "while a < 4:\n",
    "    row = names[a].split(\",\")\n",
    "    a += 1\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'steve,rodgers\\ntony,stark\\nbruce,banner\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initially we split the string on the character \\n to create a list containing three items.\n",
    "# We then loop over the list and for each item in the list we split on the character comma \n",
    "# to create a list containing first and last name. \n",
    "# We can do this in a single line as opposed to looping the names list with list of comprehension as follows:\n",
    "\n",
    "names = \"steve,rodgers\\ntony,stark\\nbruce,banner\\n\"\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve,rodgers\n",
      "tony,stark\n",
      "bruce,banner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['steve,rodgers', 'tony,stark', 'bruce,banner', '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = names.split(\"\\n\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['steve', 'rodgers'], ['tony', 'stark'], ['bruce', 'banner'], ['']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [n.split(\",\") for n in names]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['steve', 'rodgers'], ['tony', 'stark'], ['bruce', 'banner'], ['']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So in a single line we can achieve what we did in the loop.\n",
    "# Here you can see we have basically moved the loop into a one liner. \n",
    "# From both lines we can see that we get an empty list at the end of both implementations. \n",
    "# What is happening here is that at the last line return when we split on the line return we get an empty string after it. \n",
    "# So with any file where we separate on \\n we need to make sure to account for the empty string, the way we can do this\n",
    "# is refer back to the 'pop' method we introduced earlier:\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['steve', 'rodgers'], ['tony', 'stark'], ['bruce', 'banner']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\output.csv' mode='w' encoding='cp1252'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we are able to read files. \n",
    "# The next thing to cover is how to write to files. \n",
    "# It works in much the same way as for reading from files in that we \n",
    "# first need to define the file name and open a stream to write to file.\n",
    "\n",
    "file_name = \"\\\\Files\\\\output.csv\"\n",
    "file_path = x + file_name\n",
    "\n",
    "f = open(file_path,\"w\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This opens a stream under where your terminal window is open in write mode. \n",
    "# To physically write something to a file you need to define something you want to be in the file.\n",
    "\n",
    "out_str = \"something to go in the file\\n\"\n",
    "f.write(out_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something to go in the file\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we have done is create a string that we want to be in our file\n",
    "# and then using the streams method write we have written the string to file. \n",
    "# One thing we missed from the first example when we read from file is that we \n",
    "# forgot to close the file stream. \n",
    "# Here, we see in the last line that we do this using the close method. \n",
    "# Now, Python will generally tidy things like this when you quit Python or when \n",
    "# your written program ends, however its good practice to include this in your code.\n",
    "\n",
    "f = open(file_path,\"r\")\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something to go in the file\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(file_path,\"r\")\n",
    "data = f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something to go in the file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\output.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we will consider how to append to a file. \n",
    "# Now this is very similar to writing to a file. \n",
    "# However, when we open a file in write mode, we would override any existing file with the same name. \n",
    "# With append, we would keep the existing file and then add whatever we wanted to the end of it. \n",
    "# The way we do this is very similar to what we have seen before, we just use the append option \n",
    "# when opening the file, so to append to our output.csv we need to write the following:\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\output.csv' mode='a' encoding='cp1252'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(file_path,\"a\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_str = \"This is second line\\n\"\n",
    "f.write(out_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something to go in the file\\nThis is second line\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(file_path,\"r\")\n",
    "data = f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something to go in the file\n",
      "This is second line\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s expand on this example by applying reading and writing to a bigger example. \n",
    "# What we are going to do is import a dataset from sklean which is a package.\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now here we load up a dictionary object containing a dataset and relevant details that we\n",
    "# want to work on. Here, we want to take the data and feature_name keys from this dictionary\n",
    "# and write to a csv file.\n",
    "\n",
    "feature_names = boston[\"feature_names\"]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = boston[\"feature_names\"][::2]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'NOX'], dtype='<U7')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make things a little more difficult we will take every other column and not include the last two values.\n",
    "\n",
    "headers = feature_names[::2][:-2]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will give us the values that we want to put into out file. \n",
    "# So the next thing we will do is open up the file and write the headers to the file.\n",
    "\n",
    "file_name = \"\\\\Files\\\\boston_output.csv\"\n",
    "file_path = x + file_name\n",
    "\n",
    "fo = open(file_path,\"w\")\n",
    "fo.write(','.join(headers) + '\\n')\n",
    "\n",
    "# Here, we can see the output of 9 referring to the 9 characters that we wrote to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we want to do next is write the relevant data referring to the headers to the file.\n",
    "\n",
    "boston_data = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for bd in boston_data:\n",
    "    row_dict = dict(zip(feature_names, bd))\n",
    "    val_list = []\n",
    "    for h in headers:\n",
    "        val = row_dict[h]\n",
    "        val_list.append(str(val))\n",
    "out_str = ','.join(val_list)\n",
    "fo.write(out_str + '\\n')\n",
    "\n",
    "# What we have done here is assign the data to boston_data and then loop over it. \n",
    "# Each element of data can then be zipped with the feature_names to create a dictionary. \n",
    "# The reason for doing this is to allow us to select the relevant values to write to file. \n",
    "# To do this we loop over the headers and access the dictionary value using the key of the header. \n",
    "# These values are then appended to a list and the join method is applied in much the same way we \n",
    "# did for the headers to write each line to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we need to close the file, technically if we don’t do this then \n",
    "# Python will do it for us, however its good practice to do so.\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HAFIFI\\\\Documents\\\\Python Jupyter Notebook\\\\The Python Book\\\\Files\\\\boston_output.csv'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, here we have created the file to output and have written the headers to it.\n",
    "# Next, we will loop across the data and write it line by line to the file \n",
    "# making sure to select the columns that we want.\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM,NOX', '0.04741,11.93']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(file_path,\"r\")\n",
    "data = f.read().split('\\n')\n",
    "data.pop()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM,NOX\n",
      "0.04741,11.93\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(d)\n",
    "\n",
    "# That is really about it when it comes to reading, writing, and appending to files. \n",
    "# Its important to note that what we have shown only works for single sheet data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXCEL\n",
    "\n",
    "# A more common type of file that you might want to open in Python is a spreadsheet like file containing sheets of data. \n",
    "# This could be in the form of an xls or xlsx file. \n",
    "# Luckily Python has a library for us called openpyxl which allows us to write the data to an excel file and read it\n",
    "# back in as we will demonstrate.\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "feature_names = boston[\"feature_names\"]\n",
    "list(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = boston[\"feature_names\"][::2]\n",
    "list(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'NOX']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = list(feature_names)[::2][:-2]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we want to export this data into a sheet of an excel sheet.\n",
    "\n",
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "sheet1 = wb.create_sheet('boston_data', 0)\n",
    "\n",
    "# What we do here is import the relevant package and then create a Workbook. \n",
    "# For this Workbook we then create a sheet to write to and call it boston_data and insert it into position\n",
    "# 0 which is the first position of the spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for h in headers:\n",
    "    sheet1.cell(1,i,h)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we write the headers to our sheet, note we want to insert the values into the first\n",
    "# row so we set a counter i to 1 to start at the first column and then increment it to insert\n",
    "# subsequent values into the relevant columns. Here, we use the cell method where we pass\n",
    "# in row, column, and value, and here the row is fixed at 1.\n",
    "\n",
    "j = 2\n",
    "boston_data = boston['data'][0:5]\n",
    "for bd in boston_data:\n",
    "    k = 1\n",
    "    row_dict = dict(zip(feature_names, bd))\n",
    "    for h in headers:\n",
    "        val = row_dict[h]\n",
    "        sheet1.cell(j, k, val)\n",
    "        k += 1\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we look to write the first five rows of the data to the file so to do so we use the same\n",
    "# cell method, however now we need to increment rows and columns to deal with the fact\n",
    "# we have multiple rows. So to do so counters are setup outside the loop for the row and inside\n",
    "# the loop for the column. This is because we need to reset the columns for every row as we\n",
    "# want to go back to column 1, hence the k value needs to change to 1 every time we finish\n",
    "# writing a row.\n",
    "\n",
    "file_name = \"\\\\Files\\\\boston.xlsx\"\n",
    "file_path = x + file_name\n",
    "\n",
    "wb.save(file_path)\n",
    "\n",
    "# Lastly, to save the data we just use the save method on the workbook and pass in the name\n",
    "# of the file we want to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openpyxl.workbook.workbook.Workbook at 0x20a3c7e0820>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(file_path)\n",
    "wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Worksheet \"boston_data\">, <Worksheet \"Sheet\">]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet \"boston_data\">"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet = wb['boston_data']\n",
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CRIM'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then access the specific sheet using dictionary notation treating the sheet name as the key. \n",
    "# To get the values we use row and column indexes:\n",
    "\n",
    "sheet[1][0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOX'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet[1][1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00632"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet[2][0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that our columns are zero indexed despite us writing to column 1 in the code to\n",
    "# write to file but we can get the specific value by getting the value attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON\n",
    "\n",
    "# JSON stands for JavaScript Object Notation and it has become very popular as a data type and is widely used. \n",
    "# It’s described as a lightweight data-interchange format. \n",
    "# But what actually does that mean, well it’s really a text format to store data that is easy, visually, for us to \n",
    "# read and write, and also easy for the computers to parse and generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a Python user, JSON will appear to be a mixture of lists and dictionaries in that you can have collections of \n",
    "# key value pairs like in a dictionary but also have data stored in a manner like a list. \n",
    "# Let’s take the example that we have used previously and create a json representation of the data.\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = boston['feature_names'][::2]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'NOX']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = list(feature_names)[::2][:-2]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = boston['data'][0:5]\n",
    "boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'CRIM': 0.00632, 'NOX': 2.31}, {'CRIM': 0.02731, 'NOX': 7.07}, {'CRIM': 0.02729, 'NOX': 7.07}, {'CRIM': 0.03237, 'NOX': 2.18}, {'CRIM': 0.06905, 'NOX': 2.18}]\n"
     ]
    }
   ],
   "source": [
    "# So, what we have done above is what has been done previously, however here we differ by selecting only the \n",
    "# first five elements of the data which will allow us to show the data in json representation.\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for bd in boston_data:\n",
    "    row_dict = dict(zip(feature_names, bd))\n",
    "    val_dict = {}\n",
    "    for h in headers:\n",
    "        val = row_dict[h]\n",
    "        val_dict[h] = val\n",
    "    json_list.append(val_dict)\n",
    "print(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next set of code gets the data into a format to export to json. \n",
    "# As mentioned before, we can achieve this via a combination of dictionaries and lists. \n",
    "# So, initially we create a list to put every row of our data into. \n",
    "# A row can be represented as a dictionary which in this case is simply a key-value pair for two of the feature names \n",
    "# which have been assigned to the headers. \n",
    "# What we end up with is a list of dictionaries which we will look to export as json.\n",
    "\n",
    "import json\n",
    "\n",
    "file_name = \"\\\\Files\\\\boston.json\"\n",
    "file_path = x + file_name\n",
    "\n",
    "with open(file_path, 'w') as write_file:\n",
    "    json.dump(json_list, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CRIM': 0.00632, 'NOX': 2.31},\n",
       " {'CRIM': 0.02731, 'NOX': 7.07},\n",
       " {'CRIM': 0.02729, 'NOX': 7.07},\n",
       " {'CRIM': 0.03237, 'NOX': 2.18},\n",
       " {'CRIM': 0.06905, 'NOX': 2.18}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create the json output, we can use the json package and the dump method passing in the list and an open file \n",
    "# as the arguments.\n",
    "# The next part we need to cover is how to read the json file back into Python, luckily this is easily achieved using \n",
    "# the json library.\n",
    "\n",
    "import json\n",
    "\n",
    "file_name = \"\\\\Files\\\\boston.json\"\n",
    "file_path = x + file_name\n",
    "\n",
    "with open(file_path, 'r') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we did with writing to file, we just use the load method with the open file mode, read which assigns the values in \n",
    "# the file to the data object which is of type list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML\n",
    "\n",
    "# XML stands for Extensible Markup Language and much like JSON it is a way to store data that is easy visually for us to \n",
    "# read and write but at the same time easy for computers to parse and generate. \n",
    "# Unlike JSON, it doesn’t have a natural link to Python data types and so needs a bit more of an introduction into its types \n",
    "# and how it works. \n",
    "# Let’s explain using the example below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<?xml version=\"1.0\"?>\n",
    "<catalog>\n",
    "    <book id=\"bk101\">\n",
    "        <author>Rob, Mastrodomenico</author>\n",
    "        <title>The Python Book</title>\n",
    "        <genre>Computer</genre>\n",
    "        <price>120</price>\n",
    "        <publish_date>2020.03.03</publish_date>\n",
    "        <description>Stuff to help you master Python</description>\n",
    "    </book>\n",
    "    <book id=\"bk102\">\n",
    "        <author>Rob, Mastrodomenico</author>\n",
    "        <title>The Python Book 2</title>\n",
    "        <genre>Computer</genre>\n",
    "        <price>130</price>\n",
    "        <publish_date>2022.04.03</publish_date>\n",
    "        <description>It is like the first one, but much better</description>\n",
    "    </book>\n",
    "</catalog>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s deconstruct the above example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<?xml version=\"1.0\"?>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line is the xml declaration and it could have simply been written as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<?xml?>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had some specific encoding to use in the xml file we could rewrite it as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<catalog>\n",
    "</catalog>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The catalog to catalog are the root elements of the XML and are the start and end of the content. \n",
    "- The name used is arbitrary and in this case, just reflects the data we have. \n",
    "- You will notice the use of a / on the closing content, this is common between the opening and closing elements.\n",
    "- Next, we add in a further level down as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<book id=\"bk101\">\n",
    "</book>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we have defined a book using the opening book and closing book and unlike at the root level we have attached data to this level with the addition of the **id=\"bk101\"**. \n",
    "- This is the high level book data, to add more specific data about the book we can do so as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<book id=\"bk101\">\n",
    "    <author>Rob, Mastrodomenico</author>\n",
    "    <title>The Python Book</title>\n",
    "    <genre>Computer</genre>\n",
    "    <price>120</price>\n",
    "    <publish_date>2020.03.03</publish_date>\n",
    "    <description>Stuff to help you master Python</description>\n",
    "</book>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Under the book level, we have added variables for author, title, genre, price, publish_date, and description. \n",
    "- As before you can see that the definition of each variable has an opening and closing using the terminology introduced earlier.\n",
    "- Lastly, to add another book you would do so as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<book id=\"bk102\">\n",
    "    <author>Rob, Mastrodomenico</author>\n",
    "    <title>The Python Book 2</title>\n",
    "    <genre>Computer</genre>\n",
    "    <price>130</price>\n",
    "    <publish_date>2022.04.03</publish_date>\n",
    "    <description>It is like the first one, but much better</description>\n",
    "</book>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can create another book under our initial book in much the same way as we did before.\n",
    "- The way we distinguish each book is by using its own id.\n",
    "- What we have shown here is how we can build interesting data structures using XML.\n",
    "- The next question to address is how can we create and parse XML objects. \n",
    "- To do this we use lxml which is a Python library that allows the user to take advantage of the C libraries libxml2 and libxslt. \n",
    "- These are very fast XML processing libraries that are easily accessible through Python.\n",
    "- As we have done earlier in the chapter, we will use the same example and show how you can create XML from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = boston['feature_names'][::2]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'INDUS', 'NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'NOX']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = list(feature_names)[::2][:-2]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = boston['data'][0:5]\n",
    "boston_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full code to write the data to xml is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.Element(\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bd in boston_data:\n",
    "    row_dict = dict(zip(feature_names, bd))\n",
    "    row = etree.SubElement(root, \"row\")\n",
    "    for h in headers:\n",
    "        child = etree.SubElement(row, h)\n",
    "        val = row_dict[h]\n",
    "        child.text = str(val)\n",
    "        \n",
    "et = etree.ElementTree(root)\n",
    "\n",
    "file_name = \"\\\\Files\\\\boston.xml\"\n",
    "file_path = x + file_name\n",
    "\n",
    "et.write(file_path, pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking this down, we first import lxml and then create the root of our xml document."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lxml import etree\n",
    "root = etree.Element(\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to loop over the data in a similar way that we have done before to put the data into our xml."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for bd in boston_data:\n",
    "    row_dict = dict(zip(feature_names, bd))\n",
    "    row = etree.SubElement(root, \"row\")\n",
    "    for h in headers:\n",
    "        child = etree.SubElement(row, h)\n",
    "        val = row_dict[h]\n",
    "        child.text = str(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mechanism of looping the data is no different to what we have seen and we create the same row_dict and loop the headers to get the values.\n",
    "- However the difference is in how we setup the xml and where we write to. \n",
    "- For each iteration across the boston_data, we create another row called row under the root using the SubElement method assigning root as the parent. \n",
    "- Then for every value, we obtain from looping the headers we create another SubElement this time with parent row and having the name of the header. \n",
    "- We assign the value for this by setting the text attribute to be that value. \n",
    "- This then gives us the format of data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "et = etree.SubElement(root)\n",
    "et.write(file_path, pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last part is to write the data to file so we can make use of the write method by passing the root of the document through ElementTree. \n",
    "- Note that we set the pretty_print to be True, which gives the following file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<root>\n",
    "<row>\n",
    "<CRIM>0.00632</CRIM>\n",
    "<NOX>2.31</NOX>\n",
    "</row>\n",
    "<row>\n",
    "<CRIM>0.02731</CRIM>\n",
    "<NOX>7.07</NOX>\n",
    "</row>\n",
    "<row>\n",
    "<CRIM>0.02729</CRIM>\n",
    "<NOX>7.07</NOX>\n",
    "</row>\n",
    "<row>\n",
    "<CRIM>0.03237</CRIM>\n",
    "<NOX>2.18</NOX>\n",
    "</row>\n",
    "<row>\n",
    "<CRIM>0.06905</CRIM>\n",
    "<NOX>2.18</NOX>\n",
    "</row>\n",
    "</root>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will show how you can read an XML file in using lxml in Python using the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"\\\\Files\\\\boston.xml\"\n",
    "file_path = x + file_name\n",
    "\n",
    "xml = objectify.parse(open(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = xml.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = root.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element row at 0x20a3a120940>, <Element row at 0x20a3a120880>, <Element row at 0x20a3a1206c0>, <Element row at 0x20a3a120500>, <Element row at 0x20a3a120680>]\n"
     ]
    }
   ],
   "source": [
    "print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00632\n",
      "2.31\n",
      "0.02731\n",
      "7.07\n",
      "0.02729\n",
      "7.07\n",
      "0.03237\n",
      "2.18\n",
      "0.06905\n",
      "2.18\n"
     ]
    }
   ],
   "source": [
    "for c in children:\n",
    "    print(c['CRIM'])\n",
    "    print(c['NOX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we have done here is to import objectify from lxml, which will be used to read in the XML."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xml = objectify.parse(open(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we are reading in the XML file and parsing it using the parse method of objectify.\n",
    "- This gives us an XML object which we can then use to try and parse out the information.\n",
    "- Next, we look to get the root of the document using:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "root = xml.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having obtained the root, we look to get the children of this which represents the next level down which are the rows."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "children = root.getchildren()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, to access the values, we can loop through the children as that object is simply a list.\n",
    "- By doing so we can obtain and print the values as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for c in children:\n",
    "    print(c['CRIM'])\n",
    "    print(c['NOX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These refer to the values in the dataset which we created.\n",
    "- This chapter has covered some important concepts relating to files and how to read from and write to them using Python. \n",
    "- We have covered a number of different file types and given practical examples of how these work. \n",
    "- We will show later in the book other approaches to reading and writing to file but these somewhat low level approaches are very important when we want to have a high level of control when it comes to manipulating the data and are a great tool to have in your arsenal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
